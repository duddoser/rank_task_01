# -*- coding: utf-8 -*-
"""Internship_vk.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V9bksMa4bHPNugsKp2Y5cHmkII2Y9Izs
"""

!pip install catboost

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from catboost import CatBoostRanker, Pool
from sklearn.model_selection import train_test_split
from sklearn.metrics import ndcg_score, mean_squared_error
from sklearn.preprocessing import StandardScaler, label_binarize

data = pd.read_csv('intern_task.csv', sep=',')

"""**Препроцессинг и анализ входного датасета**

Для начала просто взглянем на выборку.
"""

print(data.info())
data.head(5)

"""Проверим есть ли незаполненные значения."""

df = data[data.isna().any(axis=1)]
df

"""Как видно, только в одной строке присутствуют значения NaN, поэтому просто отбросим найденную строку."""

data = data.dropna()
data = data.drop_duplicates()

"""В какой-то момент feature_119 типа object, поэтому был написан следующий блок."""

for col in data.columns:
  if data[col].dtype != np.int64 and data[col].dtype != np.float64:
    print(col)
data = data.astype({'feature_119': 'float64'})

data['feature_119'].unique()

#data.corr().style.background_gradient(cmap='coolwarm')

nan_features = ['feature_64', 'feature_65', 'feature_72', 'feature_100']
data = data.drop(nan_features, axis=1)
data.corr().style.background_gradient(cmap='coolwarm')

"""Проверив корреляцию между признаками, можно заметить, что некоторые признаки сильно линейно зависимы. Поэтому можно попробовать удалить некоторые фичи."""

linearly_dependent_columns = set()
for i in range(2, len(data.columns)):
  for j in range(i + 1, len(data.columns)):
    if i not in linearly_dependent_columns and  \
    data.iloc[:, i].corr(data.iloc[:, j]) > 0.95:
      linearly_dependent_columns.add(j)
all_columns = set([i for i in range(len(data.columns))])
good_columns = all_columns - linearly_dependent_columns
data = data.iloc[:, list(good_columns)]

data.corr().style.background_gradient(cmap='coolwarm')

data.hist(bins=30, figsize=(40, 25))

"""На графиках видно, что данные распределены неоднородно, так что немного масштабируем данные."""

scaler = StandardScaler()
scaler.fit(data.iloc[:, 2:])
data_norm = pd.DataFrame(scaler.transform(data.iloc[:, 2:]),
                         columns = data.columns[2:])

data_other = data.drop(columns = data.columns[2:])
data_new = pd.concat([data_norm, data_other], axis = 1)

"""**Обучение модели**

Разделим датасет на тренировочную, валидационную (так как используется бустинг есть вероятность переобучения) и тестовую выборку.
"""

X_train, X_test, y_train, y_test = train_test_split(data.drop('rank', axis=1),
                                                    data['rank'],
                                                    train_size=0.7,
                                                    random_state=42)
df_train = pd.DataFrame.join(X_train, y_train)
df_test = pd.DataFrame.join(X_test, y_test, how='left')
df_test = df_test.sort_values(by='query_id')
df_train, df_val  = train_test_split(df_train, test_size = 0.2, random_state=42)
df_train = df_train.sort_values(by='query_id')
df_val = df_val.sort_values(by='query_id')

target = ['rank']
features = data.columns[2:]

train_pool = Pool(
    data = df_train[features],
    label = df_train[target],
    group_id = df_train['query_id'].tolist()
)

test_pool = Pool(
    data = df_test[features],
    label = df_test[target],
    group_id = df_test['query_id'].tolist()
)

val_pool = Pool(
    data = df_val[features],
    label = df_val[target],
    group_id = df_val['query_id'].tolist()
)

"""Дальше был немного fine-tuning и подбирались гиперпараметры."""

default_parameters = {
    'iterations': 6000,
    'loss_function':'YetiRank',
    'verbose': True,
    'random_seed': 42,
    "od_type": "Iter",
    "od_wait" :15,
    "nan_mode" :"Min",
    "l2_leaf_reg":0.1,
    "rsm":0.4,
    "use_best_model":True,
    "custom_metric":'NDCG:top=5'
}

"""Для оценки модели будем использовать метрику NDCG@5"""

def ndcg_(m, df_test):
  cat_ndcg = []
  groups = np.unique(df_test['query_id'])

  for i, query in enumerate(groups):
    y = df_test[df_test['query_id'] == query][target]
    y = y.to_numpy().reshape(len(y),)
    if np.sum(y) == 0:
      continue
    result = m.predict(df_test[df_test['query_id'] == query][features])
    top_rank = np.argsort(result)[::-1]

    y = np.take(y, top_rank[:5])

    score_ndcg = ndcg_score([y], [result[top_rank[:5]]])
    cat_ndcg.append(score_ndcg)

  return np.mean(cat_ndcg)

eval_model = CatBoostRanker(**default_parameters)
eval_model.fit(train_pool, eval_set=val_pool, plot=True, use_best_model=True)

best_iteration=eval_model.get_best_iteration()
best_iteration

#eval_model.get_evals_result()

plt.figure(figsize=(10,7))
plt.plot(eval_model.evals_result_["validation"]['NDCG:top=5;type=Base'], label="Validation NDCG")
plt.xlabel("Number of trees")
plt.ylabel("Value")
plt.legend()

"""На гравике видно, что модели достаточно около 50 деревьев, для решения задачи.

NDCG = 0.7909375925271926
"""

print(ndcg_(eval_model, df_test))

"""Оценим модель и другой метрикой - MAP@5."""

default_parameters["custom_metric"]='MAP:top=5'
map_model = CatBoostRanker(**default_parameters)
map_model.fit(train_pool, eval_set=val_pool, plot=True, use_best_model=True)

#map_model.get_evals_result()

plt.figure(figsize=(10,7))
plt.plot(map_model.evals_result_["learn"]['MAP:top=5'], label="Learn MAP")
plt.plot(map_model.evals_result_["validation"]['MAP:top=5'], label="Validation MAP")
plt.xlabel("Number of trees")
plt.ylabel("Value")
plt.legend()

!pip install tensorflow_ranking

import tensorflow_ranking as tfr

y_true = []
y_pred = []
groups = np.unique(df_test['query_id'])

for i, query in enumerate(groups):
  y = df_test[df_test['query_id'] == query][target]
  y = y.to_numpy().reshape(len(y),)
  if np.sum(y) == 0:
    continue
  result = map_model.predict(df_test[df_test['query_id'] == query][features])
  top_rank = np.argsort(result)[::-1]

  y = np.take(y, top_rank[:5])
  y_true.append(y)
  y_pred.append(result[top_rank[:5]])

map_metric = tfr.keras.metrics.MeanAveragePrecisionMetric(topn=5)
map_metric(y_true, y_pred).numpy()

"""Значение метрики MAP = 0.7768964"""